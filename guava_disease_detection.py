# -*- coding: utf-8 -*-
"""Guava Disease Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/125bTNeKOItyHTXg27hW6Cjd5prRZ9xIh

# **UIT2521 - Software Development Project**  
## **Guava Plant Disease Classification and Prediction**  

**Project Team:**  
- **R. Nithyasri** (Reg. No.: 3122 22 5002 086)  
- **R. Nitish** (Reg. No.: 3122 22 5002 088)  

**Guided by:**  
- **Dr. Durga Devi**, Assistant Professor, Department of Information Technology  
- **Dr. A. Saravanan**, Assistant Professor, Department of Information Technology

### **Section 1: Mounting Google Drive and Setting Up Required Folders Alongside Machine Learning Packages**

In this section, we establish a seamless integration between Google Colab and Google Drive, allowing us to access and utilize data stored in the Drive for training and analyzing machine learning models. By mounting Google Drive, the data and necessary project files become readily accessible within the Colab environment. Additionally, we create or navigate to the required directory structure in Drive to ensure an organized workflow, keeping datasets, models, and logs systematically stored.

Alongside Drive setup, we install and import all the essential machine learning libraries and packages required for the project. This includes tools for data preprocessing, model creation, training, evaluation, and visualization. Libraries like TensorFlow/Keras are utilized for building and training deep learning models, while additional packages such as NumPy, Matplotlib, and Seaborn aid in data manipulation and graphical representation. By combining these steps, we ensure the environment is well-prepared for efficient handling, training, and evaluation of the image classification tasks.
"""

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from collections import defaultdict
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D,BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.utils import plot_model
from tensorflow.keras.callbacks import ReduceLROnPlateau
from sklearn.model_selection import train_test_split
from PIL import Image
from google.colab import drive
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

class DriveManager:
    """Handles Google Drive mounting and folder setup."""

    @staticmethod
    def mount_drive():
        drive.mount('/content/drive')
        print("Google Drive mounted.")

    @staticmethod
    def get_paths():
        paths = {
            "leaf_healthy": '/content/drive/MyDrive/SDP_Project_Dataset/Leaf_Disease_Dataset/Disease Free',
            "leaf_disease": '/content/drive/MyDrive/SDP_Project_Dataset/Leaf_Disease_Dataset',
            "leaf_disease_infected": '/content/drive/MyDrive/SDP_Project_Dataset/Leaf_Disease_Dataset/Red rust',
            "fruit_disease_phytopthora": '/content/drive/MyDrive/SDP_Project_Dataset/Fruit_Disease_Dataset/Phytopthora',
            "fruit_disease_root": '/content/drive/MyDrive/SDP_Project_Dataset/Fruit_Disease_Dataset/Root',
            "fruit_disease_scab":'/content/drive/MyDrive/SDP_Project_Dataset/Fruit_Disease_Dataset/Scab'
        }
        return paths

"""### **Section 2: Data Loading and Preprocessing - Image Augmentation and Dataset Preparation**

In this section, the dataset is loaded and prepared for training and evaluation. The images are divided into training, validation, and testing subsets to ensure proper model evaluation.

Key preprocessing steps include resizing all images to a fixed size (e.g., 224x224 pixels) for uniformity and normalizing pixel values to improve model training efficiency. Data augmentation techniques, such as random rotations, flips, zooms, and brightness adjustments, are applied to the training dataset to increase its diversity and reduce overfitting.

The images are also labeled according to their respective classes, ensuring the model can correctly associate patterns with categories during training. These steps ensure the dataset is ready for effective training and performance evaluation.
"""

import os
import cv2
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

class DataLoader:
    """Loads and preprocesses data, applying augmentations."""

    def __init__(self, leaf_disease_free, leaf_disease_infected):
        self.leaf_disease_free = leaf_disease_free
        self.leaf_disease_infected = leaf_disease_infected

    def process_and_extract_rgb(self, folder_path, label, target_size=(128, 128), augment=False):
        features, labels = [], []
        datagen = ImageDataGenerator(rotation_range=20, zoom_range=0.15, width_shift_range=0.2,
                                     height_shift_range=0.2, shear_range=0.15, horizontal_flip=True,
                                     brightness_range=[0.8, 1.2],fill_mode='nearest')

        for filename in os.listdir(folder_path):
            image_path = os.path.join(folder_path, filename)
            image = cv2.imread(image_path)
            if image is None:
                continue
            image_resized = cv2.resize(image, target_size)
            if augment:
                image_expanded = np.expand_dims(image_resized, axis=0)
                aug_iter = datagen.flow(image_expanded)
                image_resized = aug_iter[0].astype(np.uint8)
            r_mean, g_mean, b_mean = np.mean(image_resized[:, :, 0]), np.mean(image_resized[:, :, 1]), np.mean(image_resized[:, :, 2])
            features.append([r_mean, g_mean, b_mean])
            labels.append(label)
        return features, labels

    def load_data(self):
        free_features, free_labels = self.process_and_extract_rgb(self.leaf_disease_free, label=0, augment=True)
        infected_features, infected_labels = self.process_and_extract_rgb(self.leaf_disease_infected, label=1, augment=True)
        features, labels = free_features + infected_features, free_labels + infected_labels
        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)
        return X_train, X_test, y_train, y_test

    def save_to_csv(self, filename="dataset_rgb_values.csv"):
        """Saves the RGB values and labels to a CSV file."""
        free_features, free_labels = self.process_and_extract_rgb(self.leaf_disease_free, label=0, augment=True)
        infected_features, infected_labels = self.process_and_extract_rgb(self.leaf_disease_infected, label=1, augment=True)

        # Combine data
        features, labels = free_features + infected_features, free_labels + infected_labels

        # Convert to DataFrame
        data = pd.DataFrame(features, columns=["R_mean", "G_mean", "B_mean"])
        data['Label'] = labels

        # Save to CSV
        data.to_csv(filename, index=False)
        print(f"Data saved to {filename}")

class LeafDataDescriptor:
    def __init__(self, disease1_folder, disease2_folder):
        self.disease1_folder = disease1_folder
        self.disease2_folder = disease2_folder
        self.class_counts_disease1 = defaultdict(int)
        self.class_counts_disease2 = defaultdict(int)
        self.dimensions_disease1 = []
        self.dimensions_disease2 = []

    def process_images(self):
        """Process images for both diseases."""
        self._process_disease_images(self.disease1_folder, self.class_counts_disease1, self.dimensions_disease1)
        self._process_disease_images(self.disease2_folder, self.class_counts_disease2, self.dimensions_disease2)

    def _process_disease_images(self, folder, class_counts, dimensions):
        """Helper method to process images for a specific disease."""
        for root, dirs, files in os.walk(folder):
            for file in files:
                class_name = os.path.basename(root)
                class_counts[class_name] += 1
                img_path = os.path.join(root, file)

                try:
                    with Image.open(img_path) as img:
                        dimensions.append(img.size)
                except FileNotFoundError:
                    print(f"Warning: File '{img_path}' not found.")
                except Exception as e:
                    print(f"Error opening image '{img_path}': {e}")

    def print_class_counts(self):
        """Print the class counts for both diseases."""
        print("Class counts for Disease 1:")
        for class_name, count in self.class_counts_disease1.items():
            print(f"Class '{class_name}' : {count} images")

        print("\nClass counts for Disease 2:")
        for class_name, count in self.class_counts_disease2.items():
            print(f"Class '{class_name}' : {count} images")

    def calculate_average_dimensions(self):
        """Calculate and print the average image dimensions for both diseases."""
        avg_width_1, avg_height_1 = self._calculate_average_dimensions(self.dimensions_disease1)
        avg_width_2, avg_height_2 = self._calculate_average_dimensions(self.dimensions_disease2)

        print(f'\nAverage Image Dimension (Disease 1): {avg_width_1}x{avg_height_1}')
        print(f'Average Image Dimension (Disease 2): {avg_width_2}x{avg_height_2}')

    def _calculate_average_dimensions(self, dimensions):
        """Helper method to calculate average dimensions."""
        widths, heights = zip(*dimensions) if dimensions else ([], [])
        avg_width = sum(widths) / len(widths) if widths else 0
        avg_height = sum(heights) / len(heights) if heights else 0
        return avg_width, avg_height

    def display_sample_images(self, num_images=5):
        """Display the first few sample images from both diseases."""
        self._display_sample_images_from_folder(self.disease1_folder, num_images, "Disease 1")
        self._display_sample_images_from_folder(self.disease2_folder, num_images, "Disease 2")

    def _display_sample_images_from_folder(self, folder, num_images, disease_name):
        """Helper method to display sample images from a folder."""
        image_files = os.listdir(folder)
        print(f"\nDisplaying first {num_images} images from {disease_name}...")
        for i, image_file in enumerate(image_files[:num_images]):
            img_path = os.path.join(folder, image_file)
            try:
                with Image.open(img_path) as img:
                    plt.imshow(img)
                    plt.figure(figsize=(14, 14))
                    plt.show()
            except FileNotFoundError:
                print(f"Warning: Image '{img_path}' not found.")
            except Exception as e:
                print(f"Error opening image '{img_path}': {e}")

"""### **Section 4: Development of a Leaf Disease Classifier Using CNN**

In this section, a Convolutional Neural Network (CNN) is developed to classify leaf diseases. The model architecture includes convolutional, batch normalization, max-pooling, and dropout layers to extract features, reduce overfitting, and ensure efficient training. The fully connected layers use ReLU and softmax activations for classification.

The model is trained using the preprocessed dataset with a categorical cross-entropy loss function and Adam optimizer. After training, its performance is evaluated on validation and testing datasets, ensuring accurate and reliable disease classification.
"""

class LeafDiseaseClassifier:
    """Defines and trains models including CNN for classification of leaf diseases"""

    def __init__(self, input_shape=(128, 128, 3), num_classes=2, model_type='cnn'):
        """
        Initializes the classifier.

        Args:
            input_shape: Shape of input images.
            num_classes: Number of output classes (e.g., 2 for binary classification).
        """
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model =self.build_cnn()


    def build_cnn(self):
        """Builds a simple CNN model."""
        model = Sequential()
        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Conv2D(128, (3, 3), activation='relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.5))
        model.add(Dense(self.num_classes, activation='softmax'))  # softmax for binary classification

        model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])
        return model

    def train(self, train_generator, validation_generator, epochs=25):
        """Trains the current model (CNN, ResNet50, or VGG16) with the provided generators."""
        if self.model is None:
            raise ValueError("No model is defined. Please build a model first.")
        history = self.model.fit(train_generator, validation_data=validation_generator, epochs=epochs)
        return history

    def evaluate(self, validation_generator):
        """Evaluates the model on the validation set."""
        val_loss, val_accuracy = self.model.evaluate(validation_generator)
        print(f'Validation Loss: {val_loss}\nValidation Accuracy: {val_accuracy}')
        return val_loss, val_accuracy

    def plot_training_history(self, history):
        """
        Plots the training and validation accuracy and loss.

        Args:
            history: History object returned by the fit method.
        """
        plt.figure(figsize=(12, 4))

        # Accuracy plot
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'], label='Training Accuracy')
        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.title('Training and Validation Accuracy')

        # Loss plot
        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'], label='Training Loss')
        plt.plot(history.history['val_loss'], label='Validation Loss')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.legend()
        plt.title('Training and Validation Loss')

        plt.show()

    def classification_report(self, validation_generator):
        """
        Prints the classification report and confusion matrix.

        Args:
            validation_generator (ImageDataGenerator): Generator for validation data.
        """
        y_true = validation_generator.classes
        y_pred = np.argmax(self.model.predict(validation_generator), axis=-1)

        # Classification report
        print("Classification Report:\n", classification_report(y_true, y_pred, target_names=validation_generator.class_indices.keys()))

        # Confusion matrix
        conf_matrix = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(10, 8))
        sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=validation_generator.class_indices.keys(), yticklabels=validation_generator.class_indices.keys())
        plt.xlabel('Predicted Labels')
        plt.ylabel('True Labels')
        plt.title('Confusion Matrix')
        plt.show()

"""### **Section 4: Development of a Multi-Fruit Disease Classifier Using CNN**

In this section, a Convolutional Neural Network (CNN) is developed to classify diseases across multiple fruit types. The architecture includes convolutional layers for feature extraction, batch normalization for stable training, and max-pooling layers for dimensionality reduction. Dropout layers are added to prevent overfitting, while fully connected layers with ReLU and softmax activations handle multi-class classification.

The model is trained using the augmented and preprocessed dataset with a categorical cross-entropy loss function and an Adam optimizer. After training, the model is validated and tested to ensure accurate classification of fruit diseases across diverse categories.
"""

class FruitDiseaseClassifier:
    """CNN-based model for multi-class classification of plant diseases."""

    def __init__(self, input_shape=(224, 224, 3), num_classes=3):
        """
        Initializes the CNN-based multi-disease classifier.

        Args:
            input_shape (tuple): Shape of the input images.
            num_classes (int): Number of disease classes.
        """
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = self.build_cnn_model()

    def build_cnn_model(self):
        """Builds a CNN model with custom layers."""
        model = Sequential()

        # Convolutional layers with Batch Normalization and MaxPooling
        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape))
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=(2, 2)))

        model.add(Conv2D(64, (3, 3), activation='relu'))
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=(2, 2)))

        model.add(Conv2D(128, (3, 3), activation='relu'))
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=(2, 2)))

        model.add(Conv2D(256, (3, 3), activation='relu'))
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=(2, 2)))

        # Fully connected layers
        model.add(Flatten())
        model.add(Dense(512, activation='relu'))
        model.add(Dropout(0.3))


    # After BatchNormalization in convolutional layers

        model.add(Dense(self.num_classes, activation='softmax'))

        model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])
        return model

    def train(self, train_generator, validation_generator, epochs=20):
        """
        Trains the model with the provided data generators.

        Args:
            train_generator (ImageDataGenerator): Generator for training data.
            validation_generator (ImageDataGenerator): Generator for validation data.
            epochs (int): Number of training epochs.
        """
        history = self.model.fit(train_generator, validation_data=validation_generator, epochs=epochs)
        return history

    def evaluate(self, validation_generator):
        """
        Evaluates the model on the validation set.

        Args:
            validation_generator (ImageDataGenerator): Generator for validation data.

        Returns:
            Tuple of validation loss and accuracy.
        """
        val_loss, val_accuracy = self.model.evaluate(validation_generator)
        print(f'Validation Loss: {val_loss}\nValidation Accuracy: {val_accuracy}')
        return val_loss, val_accuracy

    def plot_training_history(self, history):
        """
        Plots the training and validation accuracy and loss.

        Args:
            history: History object returned by the fit method.
        """
        plt.figure(figsize=(12, 4))

        # Accuracy plot
        plt.subplot(1, 2, 1)
        plt.plot(history.history['accuracy'], label='Training Accuracy')
        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
        plt.xlabel('Epochs')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.title('Training and Validation Accuracy')

        # Loss plot
        plt.subplot(1, 2, 2)
        plt.plot(history.history['loss'], label='Training Loss')
        plt.plot(history.history['val_loss'], label='Validation Loss')
        plt.xlabel('Epochs')
        plt.ylabel('Loss')
        plt.legend()
        plt.title('Training and Validation Loss')

        plt.show()

    def classification_report(self, validation_generator):
        """
        Prints the classification report and confusion matrix.

        Args:
            validation_generator (ImageDataGenerator): Generator for validation data.
        """
        y_true = validation_generator.classes
        y_pred = np.argmax(self.model.predict(validation_generator), axis=-1)

        # Classification report
        print("Classification Report:\n", classification_report(y_true, y_pred, target_names=validation_generator.class_indices.keys()))

        # Confusion matrix
        conf_matrix = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(10, 8))
        sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=validation_generator.class_indices.keys(), yticklabels=validation_generator.class_indices.keys())
        plt.xlabel('Predicted Labels')
        plt.ylabel('True Labels')
        plt.title('Confusion Matrix')
        plt.show()

"""### **Section 5: Visualization of Model Performance**

This section visualizes the model’s performance through training and validation accuracy and loss curves, helping identify overfitting or underfitting. A confusion matrix highlights misclassified categories, while a classification report provides metrics like precision, recall, and F1-score for each class. Visualization techniques like Grad-CAM can further interpret the model’s focus areas, ensuring it learns relevant features for accurate disease classification.
"""

class Visualizer:
    """Plots training progress and visualizes sample images."""

    @staticmethod
    def plot_training_history(history):
        plt.plot(history.history['accuracy'], label='train_accuracy')
        plt.plot(history.history['val_accuracy'], label='val_accuracy')
        plt.title('Model Accuracy')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.show()

        plt.plot(history.history['loss'], label='train_loss')
        plt.plot(history.history['val_loss'], label='val_loss')
        plt.title('Model Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.show()

    @staticmethod
    def show_images(folder_path, num_images=5):
        image_files = os.listdir(folder_path)[:num_images]
        for image_file in image_files:
            img_path = os.path.join(folder_path, image_file)
            try:
                with Image.open(img_path) as img:
                    plt.imshow(img)
                    plt.figure(figsize=(5, 5))
                    plt.show()
            except Exception as e:
                print(f"Error opening image '{img_path}': {e}")

"""### **Section 6: Driver Code for Leaf Disease Classification**

The driver code integrates the entire leaf disease classification pipeline, from data preprocessing to evaluation. It begins by importing necessary libraries and preparing datasets with resizing, normalization, and augmentation. The `LeafDiseaseClassifier` model is initialized and trained on the preprocessed data using specified parameters like epochs and batch size.

The model's performance is evaluated on test data, with results visualized using accuracy/loss plots, a confusion matrix, and a classification report. The trained model is saved for future use, and predictions can be made on new images to demonstrate real-world applicability.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

DriveManager.mount_drive()
paths = DriveManager.get_paths()

data_loader = DataLoader(paths["leaf_healthy"], paths["leaf_disease_infected"])
X_train, X_test, y_train, y_test = data_loader.load_data()
data_loader.save_to_csv()

descriptor = LeafDataDescriptor(paths['leaf_healthy'], paths['leaf_disease_infected'])

descriptor.process_images()

descriptor.print_class_counts()

descriptor.calculate_average_dimensions()

descriptor.display_sample_images(num_images=5)

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
train_generator = train_datagen.flow_from_directory(paths["leaf_disease"], target_size=(128, 128),
                                                    batch_size=32, class_mode='categorical', subset='training')
validation_generator = train_datagen.flow_from_directory(paths["leaf_disease"], target_size=(128, 128),
                                                         batch_size=32, class_mode='categorical', subset='validation')


input_shape = (128, 128, 3)
num_classes = len(train_generator.class_indices)
leaf_classifier = LeafDiseaseClassifier(input_shape=input_shape, num_classes=num_classes)
model = leaf_classifier.model
plot_model(model, to_file="cnn_model.png", show_shapes=True, show_layer_names=True)

# Build and train the model (You can choose any model)

history = leaf_classifier.train(train_generator, validation_generator, epochs=10)

# Evaluate the model
leaf_classifier.evaluate(validation_generator)

# Plot training history
leaf_classifier.plot_training_history(history)

# Display classification report and confusion matrix
leaf_classifier.classification_report(validation_generator)

"""### **Section 7: Driver Code for Fruit Disease Classification**

The driver code integrates the entire leaf disease classification pipeline, from data preprocessing to evaluation. It begins by importing necessary libraries and preparing datasets with resizing, normalization, and augmentation. The `FruitDiseaseClassifier` model is initialized and trained on the preprocessed data using specified parameters like epochs and batch size.

The model's performance is evaluated on test data, with results visualized using accuracy/loss plots, a confusion matrix, and a classification report. The trained model is saved for future use, and predictions can be made on new images to demonstrate real-world applicability.
"""

# Define paths for training and validation data
train_data_path = '/content/drive/MyDrive/SDP_Project_Dataset/Fruit_Disease_Dataset'
validation_data_path = '/content/drive/MyDrive/SDP_Project_Dataset/Fruit_Disease_Dataset'

# Data augmentation and preprocessing for training and validation sets
train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2)
validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_data_path, target_size=(224, 224), batch_size=20, class_mode='categorical')
validation_generator = validation_datagen.flow_from_directory(validation_data_path, target_size=(224, 224), batch_size=10, class_mode='categorical')

# Instantiate and train the classifier
fruit_disease_classifier = FruitDiseaseClassifier(input_shape=(224, 224, 3), num_classes=train_generator.num_classes)

# Build and train the model (You can choose any model)

history = fruit_disease_classifier.train(train_generator, validation_generator, epochs=5)

# Evaluate the model
fruit_disease_classifier.evaluate(validation_generator)

# Plot training history
fruit_disease_classifier.plot_training_history(history)

# Display classification report and confusion matrix
fruit_disease_classifier.classification_report(validation_generator)